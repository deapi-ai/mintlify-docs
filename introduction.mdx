---
title: "Introduction"
description: "Fast and affordable inference for open-source AI models"
---

## What is deAPI?

deAPI provides fast and affordable inference for open-source AI models — without infrastructure overhead.

Run image, video, audio, and text workloads through a single, consistent API.

deAPI handles GPU orchestration, execution, and scaling so you can focus on building applications, not managing infrastructure.

Under the hood, deAPI runs on a global, decentralized GPU network, allowing significantly lower inference costs compared to traditional cloud providers.

---

## What you can build

With deAPI, you can power a wide range of AI applications:

- **Image generation** — Create and edit images using modern diffusion models
- **Text-to-speech** — Generate natural-sounding speech for applications and products
- **Video AI** — Video generation, transcription, and analysis
- **Document & text processing** — OCR and text extraction from documents and images
- **Multimodal workflows** — Combine text, image, audio, and video in a single application

A full, up-to-date list of supported models is available here:

<Card title="Available models" icon="microchip" href="/models">
  View all supported AI models and their capabilities
</Card>

---

## API Reference for AI Assistants

If you are building an AI agent or integrating AI assistance into your development workflow, you can use the `llms.txt` file below to give your model structured access to the complete deAPI reference.

The file provides canonical API endpoints, usage documentation, and stable links to all relevant sections of the platform. Simply include or link to this file in your AI tooling or agent configuration to enable accurate and up-to-date access to the deAPI API.

<Card title="llms.txt" icon="robot" href="https://deapi.ai/llms.txt">
  https://deapi.ai/llms.txt
</Card>